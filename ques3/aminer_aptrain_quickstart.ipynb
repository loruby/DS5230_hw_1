{"nbformat": 4, "nbformat_minor": 5, "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3"}}, "cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Aminer (AP_train) \u2014 Quickstart EDA (Beginner)\n", "\n", "This mini-notebook is tuned for the files **`AP_train.txt`** and **`readme.txt`** you were given.\n", "- Simple parsing (line by line), simple dicts and loops.\n", "- Plots with matplotlib (no seaborn), one chart per figure.\n", "- Start with a subset for speed, then run full.\n"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["# --- CONFIG ---\n", "DATA_PATH   = 'AP_train.txt'  # set to your file\n", "README_PATH = 'readme.txt'    # optional; shows format info\n", "MAX_RECORDS = None            # e.g., 200000 for testing; None for full\n", "\n", "import time\n", "import numpy as np\n", "import matplotlib.pyplot as plt\n", "from collections import defaultdict\n", "plt.rcParams['figure.figsize'] = (7,4)\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Peek at README (optional)\n", "This prints the first ~40 lines so you can confirm the expected file format."]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["try:\n", "    with open(README_PATH, 'r', encoding='utf-8', errors='ignore') as f:\n", "        for i, line in zip(range(40), f):\n", "            print(line.rstrip())\n", "except FileNotFoundError:\n", "    print('readme.txt not found; put it next to this notebook if you want to preview it.')\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Parser (Aminer format)\n", "We handle Aminer markers like `#index` (paper id), `#*` (title), `#@` (authors), `#t` (year), `#c` (venue), `#%` (reference id)."]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["def parse_aminer(path, max_records=None):\n", "    author_pub_count = defaultdict(int)\n", "    venue_pub_count  = defaultdict(int)\n", "    pub_ref_count    = {}\n", "    citations_count  = defaultdict(int)\n", "    title_by_pub     = {}\n", "    year_by_pub      = {}\n", "    venue_by_pub     = {}\n", "\n", "    total_pubs = 0\n", "    total_refs = 0\n", "\n", "    cur_id = None\n", "    cur_title = ''\n", "    cur_authors = []\n", "    cur_year = None\n", "    cur_venue = ''\n", "    cur_refs = 0\n", "\n", "    def finalize_current():\n", "        nonlocal total_pubs, cur_id, cur_title, cur_authors, cur_year, cur_venue, cur_refs\n", "        if cur_id is None:\n", "            return\n", "        title_by_pub[cur_id] = cur_title\n", "        year_by_pub[cur_id] = cur_year\n", "        venue_by_pub[cur_id] = cur_venue\n", "        pub_ref_count[cur_id] = cur_refs\n", "        total_pubs += 1\n", "        for a in cur_authors:\n", "            if a:\n", "                author_pub_count[a] += 1\n", "        if cur_venue:\n", "            venue_pub_count[cur_venue] += 1\n", "\n", "    with open(path, 'r', encoding='utf-8', errors='ignore') as f:\n", "        for line in f:\n", "            line = line.rstrip('\\n')\n", "            if not line:\n", "                continue\n", "            if line.startswith('#index'):\n", "                finalize_current()\n", "                cur_id = line[6:].strip()\n", "                cur_title = ''\n", "                cur_authors = []\n", "                cur_year = None\n", "                cur_venue = ''\n", "                cur_refs = 0\n", "                if max_records is not None and total_pubs >= max_records:\n", "                    break\n", "            elif line.startswith('#*'):\n", "                cur_title = line[2:].strip()\n", "            elif line.startswith('#@'):\n", "                s = line[2:].strip()\n", "                cur_authors = [a.strip() for a in s.split(';') if a.strip()] if s else []\n", "            elif line.startswith('#t'):\n", "                s = line[2:].strip()\n", "                try: cur_year = int(s)\n", "                except: cur_year = None\n", "            elif line.startswith('#c'):\n", "                cur_venue = line[2:].strip()\n", "            elif line.startswith('#%'):\n", "                ref_id = line[2:].strip()\n", "                if ref_id:\n", "                    citations_count[ref_id] += 1\n", "                    cur_refs += 1\n", "                    total_refs += 1\n", "        finalize_current()\n", "\n", "    return {\n", "        'author_pub_count': dict(author_pub_count),\n", "        'venue_pub_count':  dict(venue_pub_count),\n", "        'pub_ref_count':    pub_ref_count,\n", "        'citations_count':  dict(citations_count),\n", "        'title_by_pub':     title_by_pub,\n", "        'year_by_pub':      year_by_pub,\n", "        'venue_by_pub':     venue_by_pub,\n", "        'total_publications': total_pubs,\n", "        'total_references': total_refs,\n", "    }\n"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["# Run parser\n", "start = time.time()\n", "data = parse_aminer(DATA_PATH, MAX_RECORDS)\n", "print(f'Parsed in {time.time()-start:.1f}s; publications={data[\"total_publications\"]:,}, refs={data[\"total_references\"]:,}')\n", "\n", "# Quick peek of first 3 papers\n", "ids = list(data['title_by_pub'].keys())[:3]\n", "for pid in ids:\n", "    print('\\nID:', pid)\n", "    print(' title:', data['title_by_pub'].get(pid,''))\n", "    print(' year :', data['year_by_pub'].get(pid))\n", "    print(' venue:', data['venue_by_pub'].get(pid,''))\n", "    print(' refs :', data['pub_ref_count'].get(pid,0), ' | cites:', data['citations_count'].get(pid,0))\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 3.1 Basic Counts"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["authors = data['author_pub_count']\n", "venues  = data['venue_pub_count']\n", "print('Distinct authors :', len(authors))\n", "print('Distinct venues  :', len(venues))\n", "print('Publications     :', data['total_publications'])\n", "print('References (edges):', data['total_references'])\n", "print('Citations (sum)  :', sum(data['citations_count'].values()))\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 3.2 Histograms & Stats (authors / venues)\n", "We use log scale on **y** to handle heavy tails."]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["def basic_stats(arr):\n", "    arr = np.asarray(arr, dtype=float)\n", "    if arr.size == 0:\n", "        return np.nan, np.nan, np.nan, np.nan, np.nan\n", "    mean = float(np.mean(arr))\n", "    std  = float(np.std(arr, ddof=0))\n", "    q1, med, q3 = np.percentile(arr, [25, 50, 75])\n", "    return mean, std, q1, med, q3\n", "\n", "# Publications per author\n", "a_counts = np.array(list(authors.values()), dtype=float)\n", "print('Authors stats (mean, std, Q1, median, Q3):', basic_stats(a_counts))\n", "plt.figure(); plt.hist(a_counts, bins=50); plt.yscale('log'); plt.xlabel('pubs/author'); plt.ylabel('freq (log)'); plt.title('Publications per Author'); plt.show()\n", "\n", "# Publications per venue\n", "v_counts = np.array(list(venues.values()), dtype=float)\n", "print('Venues stats  (mean, std, Q1, median, Q3):', basic_stats(v_counts))\n", "if len(venues):\n", "    top_v, top_n = max(venues.items(), key=lambda kv: kv[1])\n", "    print('Top venue by publications:', top_v, top_n)\n", "plt.figure(); plt.hist(v_counts, bins=50); plt.yscale('log'); plt.xlabel('pubs/venue'); plt.ylabel('freq (log)'); plt.title('Publications per Venue'); plt.show()\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 3.3 References, Citations, Impact"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["titles   = data['title_by_pub']; years = data['year_by_pub']; venues_by = data['venue_by_pub']\n", "refs_map = data['pub_ref_count']; cites_map = data['citations_count']\n", "all_ids  = list(titles.keys())\n", "\n", "refs = np.array(list(refs_map.values()), dtype=float)\n", "cites = np.array([cites_map.get(pid,0) for pid in all_ids], dtype=float)\n", "\n", "plt.figure(); plt.hist(refs, bins=50); plt.yscale('log'); plt.xlabel('refs/paper'); plt.ylabel('freq (log)'); plt.title('References per Publication'); plt.show()\n", "plt.figure(); plt.hist(cites, bins=50); plt.yscale('log'); plt.xlabel('cites/paper'); plt.ylabel('freq (log)'); plt.title('Citations per Publication'); plt.show()\n", "\n", "max_ref_id = max(refs_map, key=refs_map.get) if refs_map else None\n", "max_cit_id = max(all_ids, key=lambda pid: cites_map.get(pid,0)) if all_ids else None\n", "print('Most references ->', max_ref_id, refs_map.get(max_ref_id,0), '|', titles.get(max_ref_id,''))\n", "print('Most citations  ->', max_cit_id, cites_map.get(max_cit_id,0), '|', titles.get(max_cit_id,''))\n", "\n", "# Venue impact (all venues)\n", "from collections import defaultdict\n", "venue_cite_sum = defaultdict(int)\n", "for pid in all_ids:\n", "    v = venues_by.get(pid,'')\n", "    if v:\n", "        venue_cite_sum[v] += cites_map.get(pid,0)\n", "impact = {v: (venue_cite_sum.get(v,0) / n) for v, n in venues.items() if n>0}\n", "imp_vals = np.array(list(impact.values()), dtype=float)\n", "plt.figure(); plt.hist(imp_vals, bins=50); plt.yscale('log'); plt.xlabel('impact'); plt.ylabel('freq (log)'); plt.title('Venue Impact (all)'); plt.show()\n", "if impact:\n", "    best_v, best_if = max(impact.items(), key=lambda kv: kv[1])\n", "    print('Highest impact venue (all):', best_v, f'{best_if:.2f}')\n", "\n", "# Impact with >=10 pubs\n", "imp10 = {v: (venue_cite_sum.get(v,0) / n) for v, n in venues.items() if n>=10}\n", "imp10_vals = np.array(list(imp10.values()), dtype=float)\n", "plt.figure(); plt.hist(imp10_vals, bins=50); plt.yscale('log'); plt.xlabel('impact (>=10 pubs)'); plt.ylabel('freq (log)'); plt.title('Venue Impact (>=10 pubs)'); plt.show()\n", "if imp10:\n", "    best_v10, best_if10 = max(imp10.items(), key=lambda kv: kv[1])\n", "    print('Highest impact venue (>=10 pubs):', best_v10, f'{best_if10:.2f}')\n", "    counts = [cites_map.get(pid,0) for pid in all_ids if venues_by.get(pid,'')==best_v10]\n", "    if counts:\n", "        print('Mean vs median citations in that venue:', float(np.mean(counts)), float(np.median(counts)))\n", "        print('First 50 citation counts:', counts[:50])\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 3.3(e) Time Trends\n", "Average references and citations per publication by year."]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["year_to_ids = defaultdict(list)\n", "for pid, yr in years.items():\n", "    if isinstance(yr, int):\n", "        year_to_ids[yr].append(pid)\n", "yrs = sorted(year_to_ids.keys())\n", "avg_refs, avg_cites = [], []\n", "for y in yrs:\n", "    ids = year_to_ids[y]\n", "    avg_refs.append(float(np.mean([refs_map.get(pid,0) for pid in ids])) if ids else 0.0)\n", "    avg_cites.append(float(np.mean([cites_map.get(pid,0) for pid in ids])) if ids else 0.0)\n", "plt.figure(); plt.plot(yrs, avg_refs, marker='o'); plt.xlabel('Year'); plt.ylabel('Avg refs'); plt.title('Avg References per Pub by Year'); plt.grid(True); plt.show()\n", "plt.figure(); plt.plot(yrs, avg_cites, marker='o'); plt.xlabel('Year'); plt.ylabel('Avg cites'); plt.title('Avg Citations per Pub by Year'); plt.grid(True); plt.show()\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Write your explanations in markdown cells:\n", "- 3.1(b): Venue name variants split counts (normalize names or map aliases).\n", "- 3.2(b): Mean vs median differences due to skew/heavy tails.\n", "- 3.3(c\u2013d): Small venues inflate impact; filtering (>=10 pubs) stabilizes. Compare mean vs median.\n", "- 3.3(e): Citations accumulate over time; references decided at publication time.\n"]}]}